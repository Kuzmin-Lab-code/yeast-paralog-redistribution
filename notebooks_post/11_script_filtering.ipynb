{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8fc199e-dfa4-450c-9a26-a9d487fe936f",
   "metadata": {},
   "source": [
    "# Quality filtering of the data\n",
    "\n",
    "Removal of the genes whose localization was mismatched with the known localizations [@Chong2015-yn], images containing abnormalities, artifacts, and excessively high heterogeneity, and the replicates containing very low cell numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17b855b9-03b2-49eb-a7ab-71381d5ee930",
   "metadata": {},
   "outputs": [],
   "source": [
    "## logging functions\n",
    "from icecream import ic as info\n",
    "import logging\n",
    "## data functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "## system functions\n",
    "from os.path import dirname\n",
    "import sys\n",
    "## system functions from roux\n",
    "from roux.lib.io import read_table\n",
    "from roux.lib.io import to_table\n",
    "## visualization functions from roux\n",
    "from roux.viz.io import to_plot\n",
    "## data functions from roux\n",
    "import roux.lib.dfs as rd # attributes\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47e6321b-a082-41fc-94a1-c94372c23240",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_path=None\n",
    "output_path=None #f'{output_dir_path}/04_filteredby_cell_counts.tsv',\n",
    "input_file_visual_inspection_path=None\n",
    "\n",
    "controls=False ## if input data is controls or not\n",
    "column_cells=None ## onto which the cutoff is applied.\n",
    "cutoff_min_cells=None ## cutoff for minimum cells per image\n",
    "cutoffs_min_cells_q=[0.01,0.05] # to show on the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c00439a3-8812-4ec9-af85-b3e32afac2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inferred parameters\n",
    "output_dir_path=dirname(output_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e8db3-5979-49ad-93c3-54466a0a9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## common functions\n",
    "def check_filter_metainfo_images_removed( #noqa\n",
    "    df0,\n",
    "    column_filter,\n",
    "    ):\n",
    "    ## check number of images per constructs that would be removed #noqa\n",
    "    df3_=(df0\n",
    "         ## select removed rows\n",
    "        .loc[df0[column_filter],:]\n",
    "         ## count images per construct \n",
    "        .groupby('label')['image id'].nunique()\n",
    "        # arrange\n",
    "        .sort_index(ascending=True).sort_values(ascending=False)\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            'label':'construct name',\n",
    "            'image id':'images removed',\n",
    "                        })     \n",
    "        )\n",
    "    logging.info(f\"-> total images {column_filter}: {df3_['images removed'].sum()}\")\n",
    "    logging.info(df3_)\n",
    "    return df3_\n",
    "\n",
    "def filter_metainfo(\n",
    "    df2,\n",
    "    controls=False,\n",
    "    ):\n",
    "    ## stats: how many rows will be removed by each of the filters\n",
    "    info(df2.filter(regex='^remove because .*').sum()/len(df2))#.any(axis=1)\n",
    "\n",
    "    df3=(\n",
    "        df2\n",
    "        .log('pairs')\n",
    "        .loc[~(df2.filter(regex='^remove because .*').any(axis=1)),:].log('pairs')\n",
    "    )\n",
    "    df3=(\n",
    "        df3\n",
    "        ## keep the ones that have all 4 constructs \n",
    "        .groupby('pairs').filter(lambda df: df['label'].nunique()==4).log('pairs')\n",
    "    )\n",
    "    df3=(\n",
    "        df3\n",
    "        ## keep the ones that have both the WT and DELTA background      \n",
    "        .groupby('pairs')\n",
    "        .filter(lambda df: df['status partner'].nunique()==2).log('pairs')\n",
    "        )\n",
    "    info(set(df2['pairs']) - set(df3['pairs']))\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42770491-aa2d-465c-8928-3a5f55bcdfe7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db503d08-bd73-49d7-baa1-8748f45fe2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.tools.io import read_pre_processed\n",
    "df0=read_pre_processed(\n",
    "    input_path,\n",
    "    rename=False,\n",
    "    )\n",
    "df0.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1de4299e-6dd1-4f2b-9700-9c62b9d8f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cells per image\n",
    "df0['cells per image']=df0.groupby(['label','replicate','URL'])['cell_id'].transform('nunique')\n",
    "## cells per replicate\n",
    "df0['cells per replicate']=df0.groupby(['label','replicate'])['cell id per pair'].transform('nunique')\n",
    "## validate that number of cells calculated with independent methods match\n",
    "assert all((df0.loc[:,['label','replicate','URL','cells per image']].drop_duplicates().groupby(['label','replicate'])['cells per image'].sum()).sort_index() == (df0.loc[:,['label','replicate','cells per replicate']].drop_duplicates().set_index(['label','replicate'])['cells per replicate']).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d860e67-b54b-4f0c-ab6a-58f93e920181",
   "metadata": {},
   "source": [
    "### Filtering based on possible artifacts identified in the visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fb7bae0-84f9-41cd-ad5d-068b7e230594",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove genes with abnormalities as detected from the visual inspections\n",
    "remove_genes=['BDF1', # localization mismatch\n",
    "              'KIN1', # no cells in the wt background\n",
    "              'YNR048W', # no cells in the delta background\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11e8266f-eae3-4cbc-8a1a-6bc578c3b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['remove because of localization mismatch']=(df0['gene symbol query'].isin(remove_genes) | df0['gene symbol partner'].isin(remove_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f856255-3bd5-49b4-a113-810acf112589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove replicates with high heterogeneity in few replicates but not all\n",
    "from roux.lib.io import read_excel\n",
    "df02=read_excel(input_file_visual_inspection_path,\n",
    "          sheet_name='Sheet1').log()\n",
    "if not controls:\n",
    "    df02=df02.log().loc[(df02['Control']!=True),:].log()\n",
    "else:\n",
    "    df1_=(df02\n",
    "    .log()\n",
    "    .loc[(df02['Control']==True),:]\n",
    "    .rd.dropby_patterns('WT')\n",
    "    .log()\n",
    "      .loc[:,['gene symbol',\n",
    "              \"replicates with abnormalities DELTA background (visual inspection)\",\n",
    "              \"images with abnormalities DELTA background (visual inspection)\",\n",
    "              \"image ids with abnormalities DELTA background (visual inspection)\",\n",
    "             \"replicates with high heterogeneity (visual inspection)\",\n",
    "             ],\n",
    "          ]\n",
    "     )  \n",
    "\n",
    "    df2_=(df02\n",
    "        .loc[((df02['gene symbol'].isin(df1_['gene symbol'].tolist())) & (df02['Control']!=True)),:]\n",
    "        .rd.dropby_patterns('DELTA')\n",
    "        .loc[:,['gene symbol',\n",
    "                      \"replicates with abnormalities WT background (visual inspection)\",\n",
    "                      \"images with abnormalities WT background (visual inspection)\",\n",
    "                      \"image ids with abnormalities WT background (visual inspection)\",]]\n",
    "        .log()  \n",
    "         )\n",
    "\n",
    "    df02=df2_.log.merge(right=df1_,\n",
    "                   on='gene symbol',\n",
    "                   how='inner',\n",
    "                  validate=\"1:1\",\n",
    "                   validate_equal_length=True,\n",
    "                  )  \n",
    "df02.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749bdf7b-dc6f-4e8d-9ffd-487901408243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns_(df):\n",
    "    \"\"\"\n",
    "    Rename columns to be compatible with `pd.concat`.\n",
    "    \"\"\"\n",
    "    return df.rename(\n",
    "                   columns={c: 'replicate' if c.startswith('replicates') else \\\n",
    "                            'URL' if c.startswith('images') else \\\n",
    "                            'image id' if c.startswith('image id') else \\\n",
    "                            c for c in df},\n",
    "                   errors='raise',\n",
    "               )\n",
    "## remove abnormalities/artifacts\n",
    "df1=pd.concat({k:(df02\n",
    "              .loc[:,['gene symbol',\n",
    "                 f\"replicates with abnormalities {k} background (visual inspection)\",\n",
    "                 f\"images with abnormalities {k} background (visual inspection)\",\n",
    "                 f\"image ids with abnormalities {k} background (visual inspection)\",\n",
    "                     ]]\n",
    "              .pipe(rename_columns_)\n",
    "               ) for k in ['WT','DELTA']},\n",
    "             axis=0,\n",
    "             names=['status partner'],\n",
    "             ).reset_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a10a13b0-eac1-4ac0-b147-0f7b0212e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## high henterogeneity replicates\n",
    "df2=(df02\n",
    ".loc[:,['gene symbol','replicates with high heterogeneity (visual inspection)']]\n",
    ".pipe(rename_columns_)\n",
    "    )\n",
    "df2=pd.concat({k:df2 for k in ['WT','DELTA']},\n",
    "          axis=0,\n",
    "          names=['status partner'],\n",
    "          ).reset_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb80f2b2-2ffc-4ad4-a83c-972ac94ce66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine all\n",
    "df3=(\n",
    "    pd.concat(\n",
    "    {\n",
    "        'artifacts':df1,\n",
    "        'high heterogeneity':df2,\n",
    "    },\n",
    "    axis=0,\n",
    "    names=['reason'],\n",
    "    )\n",
    "    .reset_index(0)\n",
    "    .log.drop_duplicates()\n",
    ")\n",
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f9c915c-a1dd-4a0f-a593-32b232587462",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df3.loc[((df3['replicate'].isnull()) & ~(df3['URL'].isnull())),:])==0, \"URLs removed irrespective of the replicate?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f241093-8113-4468-baec-f84fc939cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_table(df3,f'{output_dir_path}/02_mapped_filters/00_filters_raw.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e5478-c034-4895-b420-9c91246b9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sample_info_(\n",
    "    df1,\n",
    "    column_replicate='replicate',\n",
    "    column_image='URL',\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Format the table to be compatible with the table with sample info.  \n",
    "    \n",
    "    Note: \n",
    "        Replicate with heterogeneity=='all' means all replicates show similar heterogeneity. So NOT to be filtered out.\n",
    "    \"\"\"\n",
    "    ## ignore the rows with all the replicates showing heterogeneity\n",
    "    df1=(df1\n",
    "        .log()\n",
    "        .loc[(df1[column_replicate]!='all'),:] ## do not filter rows with 'all' value \n",
    "        .log()\n",
    "        )\n",
    "    \n",
    "    for c in [column_replicate,column_image]:\n",
    "        ## split the replicate numbers to lists in case >1\n",
    "        df1[c]=df1[c].apply(lambda x: [int(i) for i in x.split(';')] if isinstance(x,str) else np.nan if pd.isnull(x) else int(x))\n",
    "        ## split lists to separate rows\n",
    "        df1=df1.log.explode(column=c)\n",
    "        \n",
    "    ## split the 'image id's to replicate and URLs\n",
    "    df1['image id']=df1['image id'].str.strip().str.strip(';').str.split(';')\n",
    "    df1=df1.log.explode(column='image id')\n",
    "    df1['image id']=df1['image id'].replace('None', np.nan)\n",
    "    assert df1['image id'].dropna().apply(lambda x: isinstance(x,str) and ':' in x).all()\n",
    "    df1['replicate']=df1.apply(lambda x: x['image id'].split(':')[0] if not pd.isnull(x['image id']) else x['replicate'],axis=1)\n",
    "    df1['URL']=df1.apply(lambda x: x['image id'].split(':')[1] if not pd.isnull(x['image id']) else x['URL'],axis=1)\n",
    "    # assert df1['URL'].isin(['replicate1','replicate2','replicate3']).all()\n",
    "    df1=df1.drop(['image id'],axis=1)\n",
    "        \n",
    "    ## ignore the rows with missing data\n",
    "    df1=(df1\n",
    "        .log()\n",
    "        .loc[~(df1[column_replicate].isnull()),:] ## do not filter rows with 'all' value \n",
    "        .log()\n",
    "        )\n",
    "    \n",
    "    # format the replicates and the URLs\n",
    "    ## rename to be consistent with the metainfo table\n",
    "    df1[column_image]=df1[column_image].apply(lambda x: str(x).zfill(9) if not pd.isnull(x) else x)\n",
    "    df1[column_replicate]=df1[column_replicate].apply(lambda x: f\"replicate{int(x)}\" if isinstance(x,(int,float)) else x)\n",
    "    assert df1['replicate'].isin(['replicate1','replicate2','replicate3']).all(), df1['replicate'].unique()\n",
    "    \n",
    "    ## rename columns\n",
    "    df1=df1.rename(columns={'gene symbol':'gene symbol query',\n",
    "                            # column_replicate:'replicate',\n",
    "                       },errors='raise')\n",
    "    # info(df1['replicate'].value_counts())\n",
    "    return df1.log.drop_duplicates()\n",
    "df4=to_sample_info_(\n",
    "    df1=df3,\n",
    "    column_replicate='replicate',\n",
    "    column_image='URL',\n",
    "    )\n",
    "df4.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b58338-f302-4304-8736-8d2d4316c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_table(df4,f'{output_dir_path}/02_mapped_filters/01_filters_renamed.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4efd2bdc-e016-4ee3-aa01-faa469af8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_remove_rows_(\n",
    "    df0,\n",
    "    remove_images,\n",
    "    column_name,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Map the rows to be removed.\n",
    "    \"\"\"\n",
    "    assert not column_name in df0\n",
    "    df0=df0.reset_index(drop=True)\n",
    "    rows=[]\n",
    "    for d_ in remove_images:\n",
    "        rows_=df0.rd.filter_rows(d_,verbose=False).index.tolist()\n",
    "        if len(rows_)==0:\n",
    "            if df0.rd.filter_rows({k:d_[k] for k in list(d_.keys())[:-1]},verbose=False)[list(d_.keys())[-1]].nunique()!=4:\n",
    "                logging.warning(f\"rows not available in the data for {d_}, maybe the image was prefiltered.\")\n",
    "            else:\n",
    "                logging.error(f\"rows not available in the data for {d_}\")\n",
    "        rows+=rows_\n",
    "    df0[column_name]=df0.index.isin(list(set(rows)))\n",
    "    return df0\n",
    "## remove images/replicates marked from the visual inspection\n",
    "df1=map_remove_rows_(\n",
    "    df0=df0,\n",
    "        remove_images=[\n",
    "            {'gene symbol query':\"DNF1\",'replicate':[\"replicate1\",\"replicate2\"],},\n",
    "            {'label':\"CPR5-GFP CPR2-WT\",'replicate':[\"replicate3\"],'URL': [\"001013001\",\"001013003\"],},\n",
    "        ],\n",
    "        column_name='remove because of abnormalities',\n",
    "        )\n",
    "## remove images/replicates marked from the visual inspection\n",
    "df2=df1.copy()\n",
    "for column_name,df_ in df4.groupby('reason'):\n",
    "    df2=map_remove_rows_(\n",
    "        df0=df2,\n",
    "        remove_images=df_.drop(['reason'],axis=1).apply(lambda x: {key:value for key,value in x.to_dict().items() if not pd.isnull(value)},axis=1).tolist(),\n",
    "        column_name=f'remove because of {column_name}',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2a550c2-69cc-424a-905f-61369c4df069",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_table(df2,f'{output_dir_path}/02_mapped_filters.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9bc95ff-2e04-4153-adb8-a547594297ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2892efb7-212a-494e-a32a-cc35c45b420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.filter(regex='^remove because .*'):\n",
    "    ## save table\n",
    "    to_table(check_filter_metainfo_images_removed( #noqa\n",
    "    df2,\n",
    "    column_filter=col,\n",
    "    ),\n",
    "    f'{output_dir_path}/03_filtered_images_removed {col}.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede786ef-d4c1-4f4c-a806-c604d5591e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=filter_metainfo(df2,controls=controls)\n",
    "to_table(df3,f'{output_dir_path}/03_filtered.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcc8b7a8-bbfa-4389-a77e-de8c049daa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eabc12-eac9-47b9-9ff3-35676a9eba27",
   "metadata": {},
   "source": [
    "### Filtering based on the number of cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5938c6d4-80e5-4504-b2f3-8615aea2e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cells per replicate\n",
    "df3['cells per replicate (filtered)']=df3.groupby(['label','replicate'])['cell id per pair'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7be56840-ca3f-4cc0-bee2-0df08719c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterby_cells(\n",
    "    df0,\n",
    "    column_cells,\n",
    "    cutoff_min_cells,\n",
    "    cutoffs_min_cells_q,\n",
    "    output_dir_path,\n",
    "    ):\n",
    "    ## for counting and the plot\n",
    "    ### column\n",
    "    column_unit='image id' if column_cells.startswith('cells per image') else 'replicate' if column_cells.startswith('cells per replicate') else None\n",
    "    ### dataframe\n",
    "    df0_=df0.loc[:,['pairs','label']+[column_unit]+[column_cells]].drop_duplicates()\n",
    "\n",
    "    ## dataframe with cutoffs\n",
    "    df1_=(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"cutoff q\": cutoffs_min_cells_q,\n",
    "                \"cutoff\": [df0_[column_cells].quantile(q) for q in cutoffs_min_cells_q]}\n",
    "            )\n",
    "        .append(\n",
    "            pd.DataFrame({\"cutoff\":[cutoff_min_cells]})\n",
    "        )\n",
    "        .assign(\n",
    "        **{\n",
    "            'cutoff %':lambda df: df['cutoff q']*100,\n",
    "            'cutoff label':lambda df: df.apply(lambda x: f\"{x['cutoff']:.0f}\"+(f\"\\n({x['cutoff %']}%)\" if not pd.isnull(x['cutoff %']) else ''),axis=1)\n",
    "        },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # plot distribution with cutoffs\n",
    "    from modules.tools.plot import plot_dist_cutoffs\n",
    "    plot_dist_cutoffs(\n",
    "        data=df0_[column_cells],\n",
    "        df0=df1_, \n",
    "        ax=None,\n",
    "        xlim_inset=[1,40],\n",
    "        bins=100,\n",
    "        )\n",
    "    to_plot(f'{output_dir_path}/02_mapped_filters_plots/{column_cells}',fmts=['pdf','png'])\n",
    "\n",
    "    ## images/replicates removed\n",
    "    df2_=(df0_\n",
    "    .loc[(df0_[column_cells]<cutoff_min_cells),:].log()\n",
    "    .groupby(['label',])[column_unit].nunique()\n",
    "    .sort_index(ascending=True).sort_values(ascending=False)\n",
    "    .to_frame(f\"{column_unit}s removed\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\n",
    "        'label':'construct name',\n",
    "        'image ids removed':'images removed',\n",
    "                    })\n",
    "    )\n",
    "    \n",
    "    ## apply filtering selected settings\n",
    "    logging.info(f\"-> filtering by cells applied to keep the rows with >={cutoff_min_cells} {column_cells}.\")\n",
    "    column_filter=f'remove because {column_cells} < {cutoff_min_cells}'\n",
    "    df0[column_filter]=(df0[column_cells]<cutoff_min_cells)\n",
    "    return df0,column_filter\n",
    "df3,column_filter=filterby_cells(\n",
    "    df3,\n",
    "    column_cells,\n",
    "    cutoff_min_cells,\n",
    "    cutoffs_min_cells_q,\n",
    "    output_dir_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31f96dab-6f32-4033-9460-fc663d582ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save table\n",
    "to_table(check_filter_metainfo_images_removed( #noqa\n",
    "df3,\n",
    "column_filter,\n",
    "),\n",
    "f'{output_dir_path}/04_filteredby_cell_counts_images_removed {column_filter}.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebcba287-39fa-4554-bcbe-f9ac9c6bb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.pipe(filter_metainfo)\n",
    "to_table(df4,\n",
    "        output_path,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dec17d5-919d-407e-852a-2fcaeb231948",
   "metadata": {},
   "source": [
    "### Outputs: table by constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5840e052-470f-4f81-ad96-3dfe631dc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df01=read_table(f'{output_dir_path}/04_filteredby_cell_counts.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f8906dfc-f1a6-4cbf-9c96-8e7555b9186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df01.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6da960f6-06eb-4a79-a217-10cab8a15bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=(df01\n",
    ".drop(['URL','replicate','cell_id','file','Row','Column','Field','R-C','image id',\n",
    "      column_cells,\n",
    "      ]+df01.filter(regex=\"^remove because.*\").columns.tolist()+df01.filter(regex=\"^abundance.*\").columns.tolist(),\n",
    "      axis=1)\n",
    ".log.drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3158a05-8694-4e74-9911-5744c0eab47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_table(df1,f'{output_dir_path}/04_filteredby_cell_counts_byconstruct.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1c761b9-b854-4b57-8afe-be3f1b0dba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeast",
   "language": "python",
   "name": "yeast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
